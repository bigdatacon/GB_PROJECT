{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.types import StructType, StringType, IntegerType, TimestampType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, VectorAssembler, CountVectorizer, StringIndexer, IndexToString\n",
    "kafka_brokers = \"bigdataanalytics-worker-1.novalocal:6667\"  \n",
    "\n",
    "raw_orders = spark.readStream. \\\n",
    "    format(\"kafka\"). \\\n",
    "    option(\"kafka.bootstrap.servers\", kafka_brokers). \\\n",
    "    option(\"subscribe\", \"lessonpro\"). \\\n",
    "    option(\"maxOffsetsPerTrigger\", \"5\"). \\\n",
    "    option(\"startingOffsets\", \"earliest\"). \\\n",
    "    load()\n",
    "\n",
    "schema = StructType() \\\n",
    "    .add(\"number\", IntegerType()) \\\n",
    "    .add(\"housing_median_age\", DoubleType()) \\\n",
    "    .add(\"total_rooms\", DoubleType()) \\\n",
    "    .add(\"total_bedrooms\",DoubleType()) \\\n",
    "    .add(\"median_income\", DoubleType()) \\\n",
    "    .add(\"ocean_proximity\", StringType())\n",
    "\n",
    "value_sales = raw_orders.select(F.from_json(F.col(\"value\").cast(\"String\"), schema).alias(\"value\"), \"offset\")\n",
    "sales_flat = value_sales.select(F.col(\"value.*\"), \"offset\")\n",
    "\n",
    "def console_output(df, freq):\n",
    "    return df.writeStream \\\n",
    "        .format(\"console\") \\\n",
    "        .trigger(processingTime='%s seconds' % freq ) \\\n",
    "        .options(truncate=True) \\\n",
    "        .start()\n",
    "\n",
    "s = console_output(sales_flat, 5)\n",
    "s.stop()\n",
    "\n",
    "#подгружаем ML из HDFS\n",
    "pipeline_model = PipelineModel.load(\"my_LR_model8\")\n",
    "\n",
    "\n",
    "def writer_logic(df, epoch_id):\n",
    "    df.persist()\n",
    "    print(\"---------I've got new batch--------\")\n",
    "    print(\"This is what I've got from Kafka:\")\n",
    "    df.show()\n",
    "    features_from_kafka = df\n",
    "    print(\"Here is the sums from Kafka:\")\n",
    "    features_from_kafka.show()\n",
    "    cassandra_kafka_aggregation = features_from_kafka\n",
    "    cassandra_kafka_aggregation.show()\n",
    "    predict = pipeline_model.transform(cassandra_kafka_aggregation)\n",
    "    predict_short = predict.select(\"number\",\"housing_median_age\",\n",
    "                                   \"total_rooms\",\"total_bedrooms\",\"median_income\",\n",
    "                                   \"ocean_proximity\", F.col(\"prediction\").alias(\"median_house_value\"))\n",
    "    print(\"Here is what I've got after model transformation:\")\n",
    "    predict_short.show()\n",
    "    #обновляем исторический агрегат в касандре\n",
    "    predict_short.write \\\n",
    "        .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "        .options(table=\"data_test_pytrain\", keyspace=\"lessoneight\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .save()\n",
    "    print(\"I saved the prediction and aggregation in Cassandra. Continue...\")\n",
    "    df.unpersist()\n",
    "\n",
    "\n",
    "#связываем источник Кафки и foreachBatch функцию\n",
    "stream = sales_flat \\\n",
    "    .writeStream \\\n",
    "    .trigger(processingTime='100 seconds') \\\n",
    "    .foreachBatch(writer_logic) \\\n",
    "    .option(\"checkpointLocation\", \"data_test_pytrain_checkpoint\")\n",
    "\n",
    "#поехали\n",
    "s = stream.start()\n",
    "s.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
